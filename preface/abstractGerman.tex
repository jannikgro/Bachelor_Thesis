\textbf{deprecated}
Der Handel mit gebrauchten Gegenständen auf Internet-Marktplätzen ist ein wachsendes Geschäft, das sowohl im Hinblick auf die Geschäftsmöglichkeiten als auch auf die Nachhaltigkeit in Zukunft noch an Bedeutung gewinnen wird.
Auf Webshops mit diesen Artikeln zu handeln, ist jedoch aufgrund des Echtzeit-Wettbewerbs und der heftigen Preiskämpfe eine Herausforderung.
Um die Preispolitiken mit Hilfe von Reinforcement Learning zu optimieren, wird eine Simulation für Re-Commerce-Märkte eingeführt.
Nach einer geeigneten Definition der dynamischen Preisbildung als Markov-Entscheidungsprozess werden drei weit verbreitete Algorithmen auf diese Aufgabe angewendet:
Advantage Actor Critic, Deep Deterministic Policy Gradient und Soft Actor Critic.
Ziel dieser Arbeit ist es, diese Algorithmen im Hinblick auf Leistung, Stabilität und Dateneffizienz zu analysieren und zu vergleichen.
Es wurde festgestellt, dass der erst vor Kurzem eingeführte Soft Actor Critic Algorithmus die beste Leistung erbringt, während der klassische Advantage Actor Critic die höchste Trainingsstabilität bietet.
