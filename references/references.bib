@inproceedings{firstDemoReference,
  author    = {My Name and A Co-Author},
  title     = {Useless Stuff That No One Cares About},
  booktitle = {\bibstoc{coolest}{XX}},
  year      = {2025},
  pages     = {42--1337},
  publisher = ACM,
  numpages  = {1296}
}

@article{secondDemoReference,
  author    = {My Name and First Co-Author and Second Co-Author and Third Co-Author and Fourth Co-Author},
  title     = {Dear Lord! How Did This Get Accepted?},
  journal   = ZMLGM,
  year      = {2030},
  volume    = {42},
  number    = {1},
  pages     = {2--1024},
  publisher = {No Clue}
}

@article{DBLP:journals/corr/abs-1712-01815,
  author     = {David Silver and
                Thomas Hubert and
                Julian Schrittwieser and
                Ioannis Antonoglou and
                Matthew Lai and
                Arthur Guez and
                Marc Lanctot and
                Laurent Sifre and
                Dharshan Kumaran and
                Thore Graepel and
                Timothy P. Lillicrap and
                Karen Simonyan and
                Demis Hassabis},
  title      = {Mastering Chess and Shogi by Self-Play with a General Reinforcement
                Learning Algorithm},
  journal    = {CoRR},
  volume     = {abs/1712.01815},
  year       = {2017},
  url        = {http://arxiv.org/abs/1712.01815},
  eprinttype = {arXiv},
  eprint     = {1712.01815},
  timestamp  = {Mon, 13 Aug 2018 16:46:01 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1712-01815.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@book{Sutton1998,
  added-at  = {2019-07-13T10:11:53.000+0200},
  author    = {Sutton, Richard S. and Barto, Andrew G.},
  biburl    = {https://www.bibsonomy.org/bibtex/2f46601cf8b13d39d1378af0d79438b12/lanteunis},
  edition   = {Second},
  interhash = {ac6b144aaec1819919a2fba9f705c852},
  intrahash = {f46601cf8b13d39d1378af0d79438b12},
  keywords  = {},
  publisher = {The MIT Press},
  timestamp = {2019-07-13T10:11:53.000+0200},
  title     = {Reinforcement Learning: An Introduction},
  url       = {http://incompleteideas.net/book/the-book-2nd.html},
  year      = {2018 }
}

@book{deges2019grundlagen,
  title     = {Grundlagen des E-Commerce: Strategien, Modelle, Instrumente},
  author    = {Deges, F.},
  isbn      = {9783658263201},
  url       = {https://books.google.de/books?id=Fz\_ADwAAQBAJ},
  year      = {2019},
  publisher = {Springer Fachmedien Wiesbaden}
}

@inproceedings{10.5555/3044805.3044850,
  author    = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  title     = {Deterministic Policy Gradient Algorithms},
  year      = {2014},
  publisher = {JMLR.org},
  abstract  = {In this paper we consider deterministic policy gradient algorithms for reinforcement learning with continuous actions. The deterministic policy gradient has a particularly appealing form: it is the expected gradient of the action-value function. This simple form means that the deterministic policy gradient can be estimated much more efficiently than the usual stochastic policy gradient. To ensure adequate exploration, we introduce an off-policy actor-critic algorithm that learns a deterministic target policy from an exploratory behaviour policy. We demonstrate that deterministic policy gradient algorithms can significantly outperform their stochastic counterparts in high-dimensional action spaces.},
  booktitle = {Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32},
  pages     = {I–387–I–395},
  location  = {Beijing, China},
  series    = {ICML'14}
}

@article{DBLP:journals/corr/abs-1802-09477,
  author     = {Scott Fujimoto and
                Herke van Hoof and
                David Meger},
  title      = {Addressing Function Approximation Error in Actor-Critic Methods},
  journal    = {CoRR},
  volume     = {abs/1802.09477},
  year       = {2018},
  url        = {http://arxiv.org/abs/1802.09477},
  eprinttype = {arXiv},
  eprint     = {1802.09477},
  timestamp  = {Sat, 28 Sep 2019 00:58:01 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1802-09477.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{10.1145/3219819.3219833,
  author    = {Schlosser, Rainer and Boissier, Martin},
  title     = {Dynamic Pricing under Competition on Online Marketplaces: A Data-Driven Approach},
  year      = {2018},
  isbn      = {9781450355520},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3219819.3219833},
  doi       = {10.1145/3219819.3219833},
  abstract  = {Most online markets are characterized by competitive settings and limited demand information. Due to the complexity of such markets, efficient pricing strategies are hard to derive. We analyze stochastic dynamic pricing models in competitive markets with multiple offer dimensions, such as price, quality, and rating. In a first step, we use a simulated test market to study how sales probabilities are affected by specific customer behaviors and the strategic interaction of price reaction strategies. Further, we show how different state-of-the-art learning techniques can be used to estimate sales probabilities from partially observable market data. In a second step, we use a dynamic programming model to compute an effective pricing strategy which circumvents the curse of dimensionality. We demonstrate that the strategy is applicable even if the number of competitors is large and their strategies are unknown. We show that our heuristic can be tuned to smoothly balance profitability and speed of sales. Further, our approach is currently applied by a large seller on Amazon for the sale of used books. Sales results show that our data-driven strategy outperforms the rule-based strategy of an experienced seller by a profit increase of more than 20%.},
  booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery; Data Mining},
  pages     = {705–714},
  numpages  = {10},
  keywords  = {dynamic pricing, e-commerce, decision making, demand learning},
  location  = {London, United Kingdom},
  series    = {KDD '18}
}