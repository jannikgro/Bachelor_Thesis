Während Pricing ein altes Problem ist, war die Forschungsaktivität zu Pricing mit intensivem Wettbewerb und gerade auf Online-Marktplätzen bis vor einigen Jahren eher gering, wie die Übersichtsarbeit \cite{Gerpott2022} aus dem Jahre 2022 zeigt.
Demnach dominierten Monopolszenarien oder Szenarien mit starken, einschränkenden Annahmen.

Im Bereich der algorithmen- und datengetriebenen Preisoptimierung lässt sich die Schwierigkeit in zwei separate Herausforderungen unterteilen: Das Schätzen des Kundenverhaltens und das Optimieren des Pricings bei bekanntem oder erlerntem Kundenverhalten.
In \cite{10.1145/3219819.3219833} werden diese Probleme einzeln gelöst.
Zunächst werden Regressionsverfahren angewandt, um das Kundenverhalten zu erlernen.
Anschließend wird ein approximatives Dynamic-Programming-Verfahren vorgestellt, um trotz des >>Fluchs der Dimension<< Preisstrategien optimieren zu können.
Die mit diesem Verfahren optimierten Preisstrategien konnten erfolgreich auf Amazon Marketplace angewandt werden.

RL für dynamisches Pricing wurde in den letzten Jahren für spezielle Märkte angewandt, etwa den Energiemarkt bei \cite{Kim2016DynamicPA}.
Dort bestand die Aufgabe darin, mittels dynamischer Preise die Nachfrage von Energieverbrauchern gegenüber den Produzenten zu regulieren.
Es wurden tabellenbasierte Q-Learning-Verfahren angewandt und spezielle Anpassungen verglichen.
Dabei wurde auch ein Multi-Agent-Setup vorgestellt, das erheblich bessere Ergebnisse als reines Q-Learning lieferte.

In \cite{RANA2015426} wurde RL verwendet, um Preisstrategien für einen Markt zu optimieren, bei dem verderbliche Ware innerhalb eines endlichen Horizonts verkauft werden muss.
Dabei wurde nicht nur eine Produktlinie, sondern sehr viele betrachtet.
Zwischen dem Verkauf unterschiedlicher Produktlinien gibt es komplexe Abhängigkeiten, die in klassischen Pricingansätzen nicht beachtet wurden, aber mit RL mit einbezogen werden können.
Als Technologie wurde Tabular-Q-Learning mit Eligibility Traces verwendet.

Weiterhin wurde bei \cite{KRASHENINNIKOVA20198} RL für die Optimierung von Versicherungsprämien eingesetzt.
Es wurde zwar ein domänenspezifisches Modell gewählt, das aber ebenfalls eine aktuelle Marktsituation als Zustand und Preise als Aktionen verwendet.
Dabei wurden zwei Rewardfunktionen vorgeschlagen, wobei die eine nur den Gewinn bewertet, und die andere zusätzlich auch Kundenbindung.
Das genutzte RL-Verfahren heißt VQQL.
Es diskretisiert erst Zustands- und Aktionsraum, und wendet anschließend Tabular-Q-Learning an.
Bei dieser Forschungsarbeit wurde mit einer großen spanischen Versicherungsgesellschaft zusammengearbeitet und deren Echtweltdaten verwendet.

Ebenfalls mit Tabular-Q-Learning wurde in der Arbeit \cite{9086147} zur Optimierung von Cloudpreisen gearbeitet.
In diesem Anwendungsfall geht es darum, dass ein Cloudprovider Hardware beschaffen muss.
Damit muss er Kunden Clouddienstleistungen anbieten, dabei so viel Geld wie möglich erzielen, aber auch die Kundenzufriedenheit aufrechterhalten.
In der Auswertung ihrer Experimente konnten knapp 20\% mehr Profit erzielt werden als mit state-of-the-art regelbasierten Systemen.

Mit einem sehr ähnlichen Marktmodell wie bei \cite{10.1145/3219819.3219833} wurde in der Arbeit \cite{Kastius2022} RL eingesetzt, um unter Wettbewerbsbedingungen eine Preisstrategie zu optimieren.
Untersucht wurde eine \textit{Linear Economy} im Duopol und Oligopol.
Im Gegensatz zu den vorher gelisteten Arbeiten wurde hier allerdings Deep-Reinforcement-Learning eingesetzt, wie es ebenfalls Gegenstand dieser Arbeit ist.
Als RL-Verfahren wurden Deep-Q-Learning (mit diskretem Aktionsraum) und das neue, beliebte Soft-Actor-Critic-Verfahren ausprobiert.
Dabei schnitt Soft Actor Critic erheblich besser ab, aber die DQNs konnten die Aufgabe ebenfalls bewältigen.
Es wurde weiterhin festgestellt, dass im Duopol gelegentlich automatisch Kartelle gebildet werden, wenn die Kaufbereitschaft der Kunden bei höheren Preisen nicht begrenzt wird.

Auch für den Anwendungsfall der intelligenten Energieversorgung, der mit tabellenbasierten Methoden bereits bei \cite{Kim2016DynamicPA} behandelt wurde, gibt es Ansätze mit Deep-Reinforcement-Learning.
So haben \cite{8356086} Deep-Q-Learning und ein Deep-Policy-Gradient-Verfahren (REINFORCE) auf dieses Problem angewandt.
Die Resultate der Deep-Learning-basierten Verfahren wurden mit denen von Tabular Q-Learning verglichen.
Dabei wurden die Vorteile der Deep-Learning-Verfahren, insbesondere Skalierbarkeit bei hochdimensionalem Beobachtungsraum, hervorgehoben.

Während es bisher kaum detaillierte Analysen der aktuelleren RL-Verfahren im Bereich des Dynamic Pricing gibt, so wurden die Algorithmen PPO und SAC auf anderen interessanten Problemstellungen verglichen.
Bei \cite{LarsenVessel} wurden PPO, DDPG, TD3 und SAC in der Stable-Baselines-Implementierung bei autonomer Schifffahrt verglichen.
Die zu lösende Aufgabe war es, mit einem Schiff Routen zwischen Häfen zu fahren, ohne dabei mit Hindernissen zu kollidieren.
Zur Analyse wurden verschiedene Situationen getestet, bei denen die Algorithmen jeweils unterschiedlich gut abschnitten.
Nur Proximal Policy Optimization konnte jede Umgebung besser lösen als alle anderen Algorithmen und hat damit im Vergleich mit Abstand am besten abgeschnitten.

Im Bereich der unternehmensnahen Software wurden in \cite{10.1007/978-3-030-87897-9_21} die Algorithmen A2C, DDPG, TD3, PPO und SAC auf einem Problem verglichen, bei dem es darum geht, Lagerstände entlang einer Lieferkette zu optimieren.
Diese Lieferkette ist von Unsicherheiten  bei Bedarf- und Vorlaufzeiten geprägt.
Im Ergebnis übertrafen SAC und PPO die anderen Algorithmen, während sie selbst ähnlich gut abschnitten.

Zu dem konkreten Szenario, Pricing in Recommerce-Märkten mit RL-Algorithmen zu optimieren, gibt es nach dem besten Wissen noch keine wissenschaftlichen Publikationen.
Allerdings wird künstlicher Intelligenz und maschinellem Lernen eine hohe Bedeutung auf dem Weg zu einer nachhaltigeren Wirtschaft beigemessen.
So wird künstliche Intelligenz in der Konzeptstudie \cite{Jose2020} als >>Enabler<< für eine Kreislaufwirtschaft dargestellt.
Die Kreislaufwirtschaft wird in den Kontext der großen globalen und politischen Herausforderungen gestellt, Ressourcen- und Energienutzung zur Bekämpfung der globalen Klimaerwärmung zu optimieren.
Diese Kreislaufwirtschaft werde an den entscheidenden Stellen durch KI-Technologie betrieben werden.